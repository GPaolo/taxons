<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>TAXONS: PyBullet Gymperium</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">TAXONS
   &#160;<span id="projectnumber">0.1</span>
   </div>
   <div id="projectbrief">Task Agnostic eXploration of Outcome spaces through Novelty and Surprise</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('md_external_pybullet-gym_README.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">PyBullet Gymperium </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><em>PyBullet Gymperium is an open-source implementation of the OpenAI Gym MuJoCo environments for use with the OpenAI Gym Reinforcement Learning Research Platform in support of open research.</em></p>
<p>OpenAI gym is currently one of the most widely used toolkit for developing and comparing reinforcement learning algorithms. Unfortunately, for several challenging continuous control environments it requires the user to install MuJoCo, a commercial physics engine which requires a license to run for longer than 30 days. Such a commercial barrier hinders open research, especially in the perspective that other appropriate physics engines exist. This repository provides alternative implementations of the original MuJoCo environments which can be used for free. The environments have been reimplemented using <a href="https://github.com/bulletphysics/bullet3">BulletPhysics'</a> python wrapper pybullet, such that they seamlessly integrate into the OpenAI gym framework. In order to show the usability of the new environments, several RL agents from the <a href="https://github.com/reinforceio/tensorforce">Tensorforce</a> Reinforcement Learning Library are configured to be trainable out of the box. To simplify research with the implemented environment, each environment is featured with pretrained agents which serve as unit tests for the implementations and could well serve as baselines for other purposes.</p>
<h2>State of implementations</h2>
<p>Environment Name | Implemented | Similar to Reference Implementation | Pretrained agent available ------&mdash;|------&mdash;|------&mdash;|------&mdash; | <b>RoboSchool Envs</b> | InvertedPendulumPyBulletEnv-v0 | Yes | Yes | No InvertedDoublePendulumPyBulletEnv-v0 | Yes | Yes | No InvertedPendulumSwingupPyBulletEnv-v0 | Yes | Yes | No ReacherPyBulletEnv-v0 | Yes | Yes | No Walker2DPyBulletEnv-v0 | Yes | No | No HalfCheetahPyBulletEnv-v0 | Yes | No | No AntPyBulletEnv-v0 | Yes | Yes | No HopperPyBulletEnv-v0 | Yes | Yes | No HumanoidPyBulletEnv-v0 | Yes | Yes | No HumanoidFlagrunPyBulletEnv-v0 | Yes | Yes | No HumanoidFlagrunHarderPyBulletEnv-v0 | Yes | Yes | No AtlasPyBulletEnv-v0 | WIP | No | No PusherPyBulletEnv-v0 | WIP | No | No ThrowerPyBulletEnv-v0 | WIP | No | No StrikerPyBulletEnv-v0 | WIP | No | No | <b>MuJoCo Envs</b> | InvertedPendulumMuJoCoEnv-v0 | Yes | Yes | Yes InvertedDoublePendulumMuJoCoEnv-v0 | Yes | Yes | Yes ReacherMuJoCoEnv-v0 | No | No | No Walker2DMuJoCoEnv-v0 | Yes | No | No HalfCheetahMuJoCoEnv-v0 | Yes | No | No AntMuJoCotEnv-v0 | Yes | No | No HopperMuJoCoEnv-v0 | Yes | No | No HumanoidMuJoCoEnv-v0 | Yes | No | No PusherMuJoCoEnv-v0 | No | No | No ThrowerMuJoCoEnv-v0 | No | No | No StrikerMuJoCoEnv-v0 | No | No | No</p>
<p>[See What's New section below](#What's New)</p>
<h2>Basics</h2>
<p>(taken from OpenAI gym readme)</p>
<p>There are two basic concepts in reinforcement learning: the environment (namely, the outside world) and the agent (namely, the algorithm you are writing). The agent sends <code>actions</code> to the environment, and the environment replies with <code>observations</code> and <code>rewards</code> (that is, a score).</p>
<p>The core <code>gym</code> interface is <code>Env &lt;<a href="https://github.com/openai/gym/blob/master/gym/core.py">https://github.com/openai/gym/blob/master/gym/core.py</a>&gt;</code>_, which is the unified environment interface. There is no interface for agents; that part is left to you. The following are the <code>Env</code> methods you should know:</p>
<ul>
<li><code>reset(self)</code>: Reset the environment's state. Returns <code>observation</code>.</li>
<li><code>step(self, action)</code>: Step the environment by one timestep. Returns <code>observation</code>, <code>reward</code>, <code>done</code>, <code>info</code>.</li>
<li>`render(self, mode='human', close=False)<code>: Render one frame of the environment. The default mode will do something human friendly, such as pop up a window. Passing the</code>close` flag signals the renderer to close any such windows.</li>
</ul>
<p><b>In addition to the basic concepts of reinforcement learning, this framework extends the notion of an environment into two subconcepts being the robot (the agents directly controllable body) and the scene (all things the agents interacts with). Implementing RL environments in this way allows us to switch parts of the environment to generate new robot-scene combinations.</b></p>
<h2>Installing Pybullet-Gym</h2>
<p>First, you can perform a minimal installation of OpenAI Gym with </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;git clone https://github.com/openai/gym.git</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;cd gym</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;pip install -e .</div></div><!-- fragment --><p>Then, the easiest way to install Pybullet-Gym is to clone the repository and install locally </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;git clone https://github.com/benelot/pybullet-gym.git</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;cd pybullet-gym</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;pip install -e .</div></div><!-- fragment --><p>Important Note: <em>Do not</em> use <code>python setup.py install</code> as this will not copy the assets (you might get missing SDF file errors).</p>
<p>Finally, to test installation, open python and run </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;import gym  # open ai gym</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;import pybulletgym  # register PyBullet enviroments with open ai gym</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;env = gym.make(&#39;HumanoidPyBulletEnv-v0&#39;)</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;env.reset()  # should return a state vector if everything worked</div></div><!-- fragment --><h2>Supported systems</h2>
<p>We currently support Linux, Windows and OS X running Python 2.7 or 3.5.</p>
<p>To run <code>pip install -e '.[all]'</code>, you'll need a semi-recent pip. Please make sure your pip is at least at version <code>1.5.0</code>. You can upgrade using the following: <code>pip install --ignore-installed pip</code>. Alternatively, you can open <code>setup.py &lt;<a href="https://github.com/openai/gym/blob/master/setup.py">https://github.com/openai/gym/blob/master/setup.py</a>&gt;</code>_ and install the dependencies by hand.</p>
<h2>Agents</h2>
<p>As some sort of unit test for the environments, we provide pretrained agents for each environment. The agents for the roboschool envs and the mujoco were trained on the original implementations of roboschool and mujoco respectively.</p>
<h2>Environments</h2>
<p>The code for each environment group is housed in its own subdirectory <code>gym/envs &lt;<a href="https://github.com/openai/gym/blob/master/gym/envs">https://github.com/openai/gym/blob/master/gym/envs</a>&gt;</code>_. The specification of each task is in <code><a class="el" href="external_2pybullet-gym_2pybulletgym_2envs_2____init_____8py.html">gym/envs/__init__.py</a> &lt;<a href="https://github.com/openai/gym/blob/master/gym/envs/__init__.py">https://github.com/openai/gym/blob/master/gym/envs/__init__.py</a>&gt;</code>_. It's worth browsing through both.</p>
<h2>What's new</h2>
<ul>
<li>2018-01-09 Pybullet-gym is born.</li>
</ul>
<h2>Roadmap</h2>
<ol>
<li>
[ROBOSCHOOL GYMS] The current gyms are the roboschool gyms ported to pybullet. So far, most of them work well, except for the manipulator envs striker, pusher and thrower, where the robot is not correctly loaded. This will have to be fixed with Erwin Coumans. </li>
<li>
[OPENAI MUJOCO GYMS] Soon I will start to port the OpenAI gyms, which unfortunately have a slightly different observation (and probably action) vector. I can setup all the gyms quickly, but it will take a while to find out what some of observations are in mujoco and what they correspond to in pybullet. Some of the observations might not be exposed on pybullet, then we can request them, for others it is already hard to know what they are in mujoco. </li>
<li>
[OPENAI ROBOTICS GYMS] Next in line would be the robotics gyms in OpenAI. These are particularly delicate simulations and might take some tuning to even be simulatable in pybullet. 4.[DEEPMIND CONTROL SUITE] Then there is Deepmind Control Suite, another set of gyms which are in mujoco and need to be freed.  </li>
</ol>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.11 </li>
  </ul>
</div>
</body>
</html>
